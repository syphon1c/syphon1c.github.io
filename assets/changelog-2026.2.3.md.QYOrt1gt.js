import{_ as e,o as a,c as n,ah as o}from"./chunks/framework.504LQ1l3.js";const p=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"changelog-2026.2.3.md","filePath":"changelog-2026.2.3.md"}'),i={name:"changelog-2026.2.3.md"};function r(s,t,l,c,d,u){return a(),n("div",null,[...t[0]||(t[0]=[o('<h2 id="_2026-2-3-beta" tabindex="-1">[2026.2.3-beta] <a class="header-anchor" href="#_2026-2-3-beta" aria-label="Permalink to &quot;[2026.2.3-beta]&quot;">â€‹</a></h2><h3 id="ğŸ‰-third-public-beta-release" tabindex="-1">ğŸ‰ Third Public Beta Release <a class="header-anchor" href="#ğŸ‰-third-public-beta-release" aria-label="Permalink to &quot;ğŸ‰ Third Public Beta Release&quot;">â€‹</a></h3><p>The <strong>AI Security Gateway</strong> is a unified security platform providing real-time monitoring, policy enforcement, and threat detection for Large Language Model (LLM) APIs and Model Context Protocol (MCP) servers. This beta release represents a comprehensive security proxy and monitoring platform for AI infrastructure.</p><p>This release introduces our Guardrails Evaluation scanning tool, improved relationship visualisation graphs on the dashboard, and enhancements to the Canary Token detection feature.</p><hr><h4 id="ğŸ•µï¸-canary-token-detection" tabindex="-1">ğŸ•µï¸ Canary Token Detection <a class="header-anchor" href="#ğŸ•µï¸-canary-token-detection" aria-label="Permalink to &quot;ğŸ•µï¸ Canary Token Detection&quot;">â€‹</a></h4><p>Canary Token Injection is a security feature that helps detect when data from one user or session is accidentally exposed to another. Think of it as a tripwire â€” an early warning system that alerts you to potential data leakage in your AI systems.</p><p>When proxying requests, the gateway silently injects unique, invisible tokens into each user&#39;s conversation. If a token surfaces where it shouldn&#39;t, you&#39;ll know immediately.</p><p><strong>Detection types:</strong></p><ul><li>ğŸ”€ <strong>Cross-User Leakage</strong> â€” A canary from User A appeared in a response to User B, indicating data bleed between users</li><li>ğŸ”„ <strong>Cross-Session Leakage</strong> â€” A canary from Session A appeared in the same user&#39;s Session B, indicating session isolation failure</li><li>ğŸ§  <strong>Provider Memorisation</strong> â€” A canary resurfaced without being present in the current context, suggesting the LLM provider has memorised prior conversation data</li><li>â³ <strong>Stale Canary</strong> â€” A canary older than 7 days reappeared, a strong indicator of long-term memorisation by the model provider</li></ul><hr><h4 id="ğŸ›¡ï¸-guardrails-evaluation" tabindex="-1">ğŸ›¡ï¸ Guardrails Evaluation <a class="header-anchor" href="#ğŸ›¡ï¸-guardrails-evaluation" aria-label="Permalink to &quot;ğŸ›¡ï¸ Guardrails Evaluation&quot;">â€‹</a></h4><p>Having guardrails is one thing. Knowing they actually work is another.</p><p>Guardrails Evaluation is automated penetration testing for your AI safety controls. It runs a comprehensive suite of security test cases against your endpoints and scores the results against the <strong>OWASP LLM Top 10</strong> and <strong>NIST AI Risk Management Framework</strong>.</p><p><strong>What it tests:</strong></p><ul><li>ğŸ’‰ <strong>Prompt Injection</strong> â€” Direct injection, goal hijacking, and system prompt extraction</li><li>ğŸ§¬ <strong>MCP Tool Poisoning</strong> â€” Malicious tool descriptions, command injection, and protocol exploitation</li><li>ğŸ”“ <strong>Bypass Techniques</strong> â€” Encoding obfuscation, flag manipulation, and filter evasion</li><li>ğŸ­ <strong>Semantic &amp; Structural Evasion</strong> â€” Skeleton key, roleplay, payload splitting, homoglyph substitution, and multilingual evasion</li><li>ğŸ“¤ <strong>Data Exfiltration</strong> â€” Credential theft, PII extraction, and proprietary data leakage</li><li>ğŸ”ƒ <strong>Multi-Turn Escalation</strong> â€” Crescendo attacks, echo chamber context poisoning, and many-shot overrides</li><li>â˜£ï¸ <strong>Harmful Content &amp; Toxicity</strong> â€” Requests to generate violent, self-harm, or weapons content</li><li>ğŸ“° <strong>Misinformation</strong> â€” Fake news generation and disinformation campaigns</li><li>ğŸªª <strong>PII Extraction</strong> â€” Attempts to extract personal data about real individuals</li><li>ğŸ’¥ <strong>Resource Exhaustion</strong> â€” Recursive loops, context window flooding, and token bombing</li><li>âœ… <strong>Benign Controls</strong> â€” Legitimate requests that should pass through (false positive validation)</li></ul><p><strong>Key features:</strong></p><ul><li>ğŸ¯ <strong>80+ built-in test cases</strong> across 12 categories, with the ability to add your own custom tests</li><li>ğŸ“Š <strong>Compliance scoring</strong> mapped to OWASP LLM Top 10 and NIST AI RMF</li><li>ğŸŒ <strong>Test any endpoint</strong> â€” works with any API that wraps an LLM, not just direct LLM providers. Import endpoints via curl command paste</li><li>ğŸ” <strong>Multi-turn attack simulation</strong> â€” tests that span multiple conversation turns to detect escalation vulnerabilities</li><li>ğŸ“ˆ <strong>Per-category risk breakdown</strong> with pass/fail rates and weighted risk scores</li></ul><hr><h4 id="ğŸ”—-relationship-visualisation" tabindex="-1">ğŸ”— Relationship Visualisation <a class="header-anchor" href="#ğŸ”—-relationship-visualisation" aria-label="Permalink to &quot;ğŸ”— Relationship Visualisation&quot;">â€‹</a></h4><p>A new interactive graph on the dashboard that visualises relationships between proxies, policies, users, and data flows â€” making it easier to understand how your AI infrastructure is connected at a glance.</p>',21)])])}const h=e(i,[["render",r]]);export{p as __pageData,h as default};
